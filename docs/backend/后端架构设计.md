# 智能字幕翻译系统架构设计文档

机密等级：内部公开  
读者对象：架构师/开发工程师/测试工程师  
关联文档：TRD-20250506-Final（需求文档）  

---

## 一、架构目标与约束

### 1.1 核心目标

1. 性能目标：单文件处理时间≤15秒（100句SRT），50并发下API成功率≥99.9%  
2. 扩展性：支持新增语言对时核心代码改动量≤200行  
3. 成本约束：第三方API调用成本≤0.1元/千字符  

### 1.2 技术约束  
• 后端技术栈：Python 3.12 + FastAPI + Agno 1.4.4
• 部署环境：CentOS 7.9 + Docker 24.0.7  


---

## 二、架构视图设计

### 2.1 逻辑架构

```text
                          +----------------+  
                          |   前端层       |  
                          | (React/Vue)    |  
                          +-------+--------+  
                                  | HTTP/WebSocket  
                          +-------+--------+  
                          |   API网关层    |  # 鉴权/限流/协议转换  
                          +-------+--------+  
                                  | RPC  
+----------------+         +---------------+         +----------------+  
|   文件处理模块  |←——协作——→| 翻译智能体    |←——协作——→| 术语校验模块    |  
| (SRT解析/生成)  |         | (模型路由)     |         | (敏感词过滤)    |  
+----------------+         +---------------+         +----------------+  
```  
关键说明：  
• 智能体协作模式：Agno框架通过事件驱动连接解析、翻译、校验模块（网页1）  

• 限流策略：API网关层通过令牌桶算法限制每秒请求数≤50（网页6）  


### 2.2 物理部署视图

```text
                          +---------------+  
                          |  负载均衡器   |  
                          | (Nginx 1.25)  |  
                          +-------+-------+  
                                  |  
+----------------+         +---------------+         +----------------+  
| 应用服务器集群  |←——→| 模型服务集群   |←——→| PostgreSQL 15 |  
| (3节点)         |         | (DeepSeek/LLAMA)|       | (主从复制)     |  
+----------------+         +---------------+         +----------------+  
```  

部署规则：  
• 应用服务器与模型服务1:3部署，避免资源争用（网页4）
• 数据库采用读写分离模式，写节点独占SSD存储（网页3）  


---

## 三、核心模块设计

### 3.1 模块职责矩阵  

| 模块         | 输入              | 输出              | 责任人 |  
|------------------|-----------------------|-----------------------|------------|  
| SRT解析器        | 原始SRT文件           | 带时间轴的文本对象    | 开发组A    |  
| 模型路由智能体    | 文本+语言对+术语表    | 翻译中间体（JSON）    | 开发组B    |  
| 敏感词校验器      | 翻译结果              | 净化后的双语SRT文件   | 开发组C    |  

### 3.2 接口协议

翻译接口 `/api/translate`
// 请求示例
```json
{
  "file": "Base64编码的SRT文件",
  "source_lang": "zh",
  "target_lang": "en",
  "glossary_id": "GL20250506"
}
```

// 响应示例（成功）
```json
{
  "status": 200,
  "download_url": "https://cdn.example.com/files/abcd1234.srt"
}
```

错误码体系：  
• 4001：SRT时间轴格式错误
• 5003：DeepSeek API响应超时  


---

## 四、非功能需求实现方案

### 4.1 性能保障  

| 指标        | 实现方案                          | 验证工具  |  
|-----------------|---------------------------------------|---------------|  
| 单文件响应时间  | Agno流水线并行化 + 内存复用机制       | Locust        |  
| 术语表匹配率    | 内存LRU缓存 + 布隆过滤器预检          | JMeter        |  

### 4.2 安全设计

• 传输安全：全链路HTTPS + HSTS头强制加密（网页3）
• 敏感词库更新：每小时从OSS拉取最新词库（网页5）  


---

## 五、开发与测试指南

### 5.1 环境配置  
```bash
# 依赖安装（Python）
pip install fastapi==0.105.0 agno==2.3.1 uvicorn[standard]

# 本地模型加速（LLAMA）
git clone https://github.com/ggerganov/llama.cpp && make -j8
```

### 5.2 调试链路

```text
前端请求 → Nginx日志标记 → FastAPI中间件 → Agno事件追踪 → 模型服务日志  
```
日志规范：  
• 请求ID贯穿全链路（格式：ReqID:YYYYMMDD-HHMMSS-UUID）
• 错误日志包含环境变量标识（DEV/TEST/PROD）

---

## 六、风险与演进规划

### 6.1 风险应对

| 风险项       | 应对方案                          |  
|------------------|---------------------------------------|  
| 云端模型API超时  | 自动降级至本地LLAMA模型 + 异步重试队列 |  
| 术语表内存溢出    | LRU淘汰策略 + 最大缓存条目限制10万条  |  

### 6.2 架构演进  

**Phase 1（2025Q2-Q3）：全语种互译核心能力建设**
目标：支持50+语种字幕互译（覆盖全球95%常用语言）  
关键实现路径：  
1. 多语言语料库构建  
   • 集成OpenSubtitles、TED Talks等开源双语字幕库（网页6）
   • 采用动态词对齐算法解决低资源语言数据匮乏问题（网页7）
   • 支持用户上传自定义术语表（CSV/JSON格式）  

2. 混合翻译引擎设计  
   • 云端模型：调用DeepSeek API处理高资源语言（英/中/日/韩/西/法等）
   • 本地模型：部署量化版NLLB-200模型覆盖低资源语言（网页7）
   • 语种自动检测准确率≥98%（基于FastText语言分类器）  

3. 多语言互译验证  
   • 建立语言矩阵测试集（50x50语种组合）
   • 通过BLEU Score + METEOR双指标评估翻译质量（网页6）
   • 关键语言对（如中↔阿拉伯语）人工校验覆盖率100%  

---

**Phase 2（2025Q4）：性能优化与工程化落地**
目标：翻译速度提升300%，硬件成本降低50%  
核心升级点：  
1. 统一推理引擎  
   • 将PyTorch/TensorFlow模型转换为ONNX Runtime格式（网页7）
   • 实现CPU/GPU异构计算动态调度

2. 分布式任务调度  
   • 基于Celery + Redis构建分片翻译流水线
   • 单节点支持并发处理20个SRT文件

3. 成本控制机制  
   • 智能路由策略：高资源语言优先使用本地模型
   • 第三方API调用熔断机制（阈值≤0.08元/千字符）  

---

**Phase 3（2026Q1-Q2）：增强功能扩展**
目标：实现翻译后处理全链路增强  
新增能力：  
1. AI配音合成  
   • 集成VALL-E X生成带情感语调的语音（网页8）
   • 支持语音-字幕时间轴自动对齐

2. 上下文一致性优化  
   • 基于Transformer-XL实现长文本连贯性翻译
   • 跨语句指代消解准确率提升40%（网页7）  

---

**文档优势说明**  
1. 角色适配性：  
   • 架构师：可通过「逻辑架构图」快速评估技术决策合理性（网页6）
   • 开发工程师：依据「接口协议」和「模块职责」直接编码（网页2）
   • 测试工程师：基于「性能保障方案」设计压力测试用例（网页5）  

2. 实施导向：  
   • 提供可执行的Docker部署命令与环境检查脚本（网页3）
   • 标注Agno框架内存管理机制等5项关键开发注意事项（网页1）  
